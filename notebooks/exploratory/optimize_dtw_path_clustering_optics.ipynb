{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "current_dir = os.getcwd()\n",
    "parent_parent_dir = os.path.abspath(os.path.join(current_dir, '../..')) # tweak so that you get dir of code project\n",
    "\n",
    "sys.path.append(parent_parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.cluster import OPTICS\n",
    "from src.features.get_first_and_last_x_y_coordinates import get_first_and_last_x_y_coordinates\n",
    "from src.features.get_x_y_tuple_list import get_x_y_tuple_list\n",
    "from src.models.DISTANCE_METRICS_WITH_ADDITIONAL_ARGS import DISTANCE_METRICS_WITH_ADDITIONAL_ARGS\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.optimize import linprog\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.metrics import silhouette_score\n",
    "import re\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dtw_matrices_from_json(file_path):\n",
    "    \"\"\"\n",
    "    Load the DTW distance matrices from a JSON file.\n",
    "\n",
    "    :param file_path: The path to the JSON file containing DTW matrices.\n",
    "    :return: A dictionary where the keys are parameter names and the values are the DTW matrices (as NumPy arrays).\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        dtw_matrices_dict = json.load(json_file)\n",
    "\n",
    "    # Convert the matrices from lists back to NumPy arrays\n",
    "    dtw_matrices_dict = {key: np.array(matrix) for key, matrix in dtw_matrices_dict.items()}\n",
    "\n",
    "    return dtw_matrices_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimization parameters\n",
    "# max_eps_range = np.arange(20, 500, 30)  # 16 values\n",
    "# min_samples_range = np.arange(3, 10, 1)  # 7 values\n",
    "# xi_range = np.arange(0.01, 0.5, 0.05)  # 10 values\n",
    "# cluster_methods = ['dbscan', 'xi']  # 2 values\n",
    "\n",
    "max_eps_range = np.arange(20, 510, 20)  # 16 values\n",
    "min_samples_range = np.arange(3, 10, 1)  # 7 values\n",
    "xi_range = np.arange(0.01, 0.2, 0.02)  # 10 values\n",
    "cluster_methods = ['dbscan', 'xi']  # 2 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define intersection names\n",
    "# intersection_names = ['k733_2020', 'k733_2018']\n",
    "intersection_names = ['k729_2022']\n",
    "# intersection_names.append('k729_2022')\n",
    "print(intersection_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_three_letter_uid(max_eps_range, min_samples_range, xi_range):\n",
    "    \"\"\"\n",
    "    Create a 3-letter unique ID based on optimization parameters.\n",
    "    \"\"\"\n",
    "    # Take the first letter of 'max_eps', 'min_samples', and 'xi' ranges for uniqueness\n",
    "    max_eps_id = chr(65 + int(max(max_eps_range)) % 26)  # Convert max_eps to a letter\n",
    "    min_samples_id = chr(65 + int(min(min_samples_range)) % 26)  # Convert min_samples to a letter\n",
    "    xi_id = chr(65 + int(min(xi_range) * 100) % 26)  # Convert xi to a letter based on its percentage\n",
    "\n",
    "    # Combine them to form a 3-letter ID\n",
    "    uid = f\"{max_eps_id}{min_samples_id}{xi_id}\"\n",
    "    return uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize for each score individually\n",
    "\n",
    "from src.models.optics.optimize_optics_for_precomputed_dtw import optimize_optics_for_precomputed_dtw\n",
    "from src.data.save_optimization_parameters_in_json_file import save_optimization_parameters_in_json_file\n",
    "\n",
    "for intersection_name in intersection_names:\n",
    "    data_path = f'{parent_parent_dir}/data/processed/{intersection_name}_cuid.csv'\n",
    "\n",
    "    df_cuid = pd.read_csv(data_path)\n",
    "    df_cuid_grouped_path = data_path.replace('.csv', '_grouped.csv')\n",
    "    df_cuid_grouped = pd.read_csv(df_cuid_grouped_path)\n",
    "    df_cuid_grouped['x'] = df_cuid_grouped['x'].apply(lambda x: ast.literal_eval(x))\n",
    "    df_cuid_grouped['y'] = df_cuid_grouped['y'].apply(lambda y: ast.literal_eval(y))\n",
    "    list_x_y_tuples = get_x_y_tuple_list(df_cuid_grouped, ['x','y'])\n",
    "\n",
    "    dtw_matrices_dict = load_dtw_matrices_from_json(f'{parent_parent_dir}/data/processed/{intersection_name}_diff_itakura_slope_dtw_matrices.json')\n",
    "\n",
    "\n",
    "\n",
    "    optimization_results_optics = optimize_optics_for_precomputed_dtw(dtw_matrices_dict,\n",
    "                                                                                    max_eps_range=max_eps_range,\n",
    "                                                                                    min_samples_range=min_samples_range,\n",
    "                                                                                    cluster_methods=cluster_methods,\n",
    "                                                                                    xis=xi_range,\n",
    "                                                                                    n_jobs=-1)\n",
    "    print(optimization_results_optics)\n",
    "\n",
    "\n",
    "    optimization_results_optics['used_parameters'] = {\n",
    "        \"max_eps_range\": list(max_eps_range),\n",
    "        \"min_samples_range\": list(min_samples_range),\n",
    "        \"cluster_methods\": cluster_methods,\n",
    "        \"xi_range\": list(xi_range)\n",
    "    }\n",
    "\n",
    "    unique_id = create_three_letter_uid(max_eps_range, min_samples_range, xi_range)\n",
    "    unique_filename = f'{intersection_name}_optics_vehicle_paths_optimized_no_outliers_params_{unique_id}.json'\n",
    "\n",
    "    save_optimization_parameters_in_json_file(f'{parent_parent_dir}/data/processed/{unique_filename}', **optimization_results_optics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize with accumulating scores\n",
    "\n",
    "from src.models.optics.optimize_optics_accum_scores_precomputed_dtw import optimize_optics_accum_scores_precomputed_dtw\n",
    "from src.data.save_optimization_parameters_in_json_file import save_optimization_parameters_in_json_file\n",
    "\n",
    "\n",
    "for intersection_name in intersection_names:\n",
    "    data_path = f'{parent_parent_dir}/data/processed/{intersection_name}_cuid.csv'\n",
    "\n",
    "    df_cuid = pd.read_csv(data_path)\n",
    "    df_cuid_grouped_path = data_path.replace('.csv', '_grouped.csv')\n",
    "    df_cuid_grouped = pd.read_csv(df_cuid_grouped_path)\n",
    "    df_cuid_grouped['x'] = df_cuid_grouped['x'].apply(lambda x: ast.literal_eval(x))\n",
    "    df_cuid_grouped['y'] = df_cuid_grouped['y'].apply(lambda y: ast.literal_eval(y))\n",
    "\n",
    "    dtw_matrices_dict = load_dtw_matrices_from_json(f'{parent_parent_dir}/data/processed/{intersection_name}_diff_itakura_slope_dtw_matrices.json')\n",
    "\n",
    "\n",
    "\n",
    "    optimization_results_optics = optimize_optics_accum_scores_precomputed_dtw(dtw_matrices_dict,\n",
    "                                                                                    max_eps_range=max_eps_range,\n",
    "                                                                                    min_samples_range=min_samples_range,\n",
    "                                                                                    cluster_methods=cluster_methods,\n",
    "                                                                                    xis=xi_range,\n",
    "                                                                                    n_jobs=-1)\n",
    "    print(optimization_results_optics)\n",
    "\n",
    "    optimization_results_optics['used_parameters'] = {\n",
    "        \"max_eps_range\": list(max_eps_range),\n",
    "        \"min_samples_range\": list(min_samples_range),\n",
    "        \"cluster_methods\": cluster_methods,\n",
    "        \"xi_range\": list(xi_range)\n",
    "    }\n",
    "\n",
    "    unique_id = create_three_letter_uid(max_eps_range, min_samples_range, xi_range)\n",
    "    unique_filename = f'{intersection_name}_optics_vehicle_paths_optimized_no_outliers_params_acc_score_{unique_id}.json'\n",
    "\n",
    "    save_optimization_parameters_in_json_file(f'{parent_parent_dir}/data/processed/{unique_filename}', **optimization_results_optics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ba_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
