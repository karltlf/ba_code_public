{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "target_dir_name = 'ba_code_project'\n",
    "while True:\n",
    "    # Check if the target directory exists in the current directory\n",
    "    potential_target = os.path.join(current_dir, target_dir_name)\n",
    "    if os.path.isdir(potential_target):\n",
    "        code_root_dir = potential_target\n",
    "        break\n",
    "    # Move one level up\n",
    "    parent_dir = os.path.dirname(current_dir)\n",
    "    # If we're at the root of the file system and still haven't found it, stop\n",
    "    if parent_dir == current_dir:\n",
    "        code_root_dir = None\n",
    "        break\n",
    "    current_dir = parent_dir\n",
    "if code_root_dir:\n",
    "    # Add the found target directory to sys.path\n",
    "    sys.path.append(code_root_dir)\n",
    "else:\n",
    "    print(f'Target directory not found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from src.features.get_first_and_last_x_y_coordinates import get_first_and_last_x_y_coordinates\n",
    "from src.features.get_x_y_tuple_list import get_x_y_tuple_list\n",
    "from src.visualization.plot_vehicle_tracks_in_notebook import plot_vehicle_tracks_in_notebook\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to access while testing\n",
    "# intersection_name = 'k729_2022'\n",
    "# intersection_name = 'k733_2018'\n",
    "intersection_name = 'k733_2020'\n",
    "data_path = f'{code_root_dir}/data/processed/{intersection_name}_cuid.csv'\n",
    "\n",
    "df_cuid = pd.read_csv(data_path)\n",
    "df_cuid_grouped_path = data_path.replace('.csv', '_grouped.csv')\n",
    "df_cuid_grouped = pd.read_csv(df_cuid_grouped_path)\n",
    "df_cuid_grouped['x'] = df_cuid_grouped['x'].apply(lambda x: ast.literal_eval(x))\n",
    "df_cuid_grouped['y'] = df_cuid_grouped['y'].apply(lambda y: ast.literal_eval(y))\n",
    "list_x_y_tuples = get_x_y_tuple_list(df_cuid_grouped, ['x','y'])\n",
    "first_last_x_coords, first_last_y_coords = get_first_and_last_x_y_coordinates(list_x_y_tuples)\n",
    "X_intersection = np.array([first_last_x_coords, first_last_y_coords]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_cuid_grouped['track_id']))\n",
    "print(intersection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot simple dtw alignment + cost matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# =========================\n",
    "# Step 1: Define Two Unique Sample Sequences\n",
    "# =========================\n",
    "\n",
    "# Define unique sequences for clarity\n",
    "sequence_a = np.array([2, 5, 8, 11])\n",
    "sequence_b = np.array([1, 3, 5, 7, 9, 10, 12])\n",
    "\n",
    "# =========================\n",
    "# Step 2: Compute the Cost Matrix\n",
    "# =========================\n",
    "\n",
    "cost_matrix = cdist(sequence_a[:, np.newaxis], sequence_b[:, np.newaxis], metric='euclidean')\n",
    "\n",
    "# =========================\n",
    "# Step 3: Compute the Accumulated Cost Matrix (DTW Matrix)\n",
    "# =========================\n",
    "\n",
    "accumulated_cost = np.full((len(sequence_a), len(sequence_b)), np.inf)\n",
    "accumulated_cost[0, 0] = cost_matrix[0, 0]\n",
    "\n",
    "for j in range(1, len(sequence_b)):\n",
    "    accumulated_cost[0, j] = cost_matrix[0, j] + accumulated_cost[0, j-1]\n",
    "for i in range(1, len(sequence_a)):\n",
    "    accumulated_cost[i, 0] = cost_matrix[i, 0] + accumulated_cost[i-1, 0]\n",
    "for i in range(1, len(sequence_a)):\n",
    "    for j in range(1, len(sequence_b)):\n",
    "        accumulated_cost[i, j] = cost_matrix[i, j] + min(\n",
    "            accumulated_cost[i-1, j-1],  # Diagonal (Match)\n",
    "            accumulated_cost[i-1, j],    # Left (Insertion)\n",
    "            accumulated_cost[i, j-1]     # Up (Deletion)\n",
    "        )\n",
    "\n",
    "# =========================\n",
    "# Step 4: Compute the Optimal Warping Path\n",
    "# =========================\n",
    "\n",
    "i, j = len(sequence_a) - 1, len(sequence_b) - 1\n",
    "path = [(i, j)]\n",
    "while i > 0 or j > 0:\n",
    "    if i == 0:\n",
    "        j -= 1\n",
    "    elif j == 0:\n",
    "        i -= 1\n",
    "    else:\n",
    "        choices = [\n",
    "            accumulated_cost[i-1, j-1],\n",
    "            accumulated_cost[i-1, j],\n",
    "            accumulated_cost[i, j-1]\n",
    "        ]\n",
    "        move = np.argmin(choices)\n",
    "        if move == 0:\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif move == 1:\n",
    "            i -= 1\n",
    "        else:\n",
    "            j -= 1\n",
    "    path.append((i, j))\n",
    "\n",
    "path = np.array(path[::-1])\n",
    "\n",
    "# =========================\n",
    "# Plot 1: Sequences Alignment with DTW Path\n",
    "# =========================\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(10, 8))\n",
    "ax1.plot(range(len(sequence_a)), sequence_a, marker='o', label='Sequence A', color='blue', markersize=8, linewidth=2)\n",
    "ax1.plot(range(len(sequence_b)), sequence_b, marker='s', label='Sequence B', color='green', markersize=8, linewidth=2)\n",
    "\n",
    "for (i, j) in path:\n",
    "    ax1.plot([i, j], [sequence_a[i], sequence_b[j]], 'r--', linewidth=1.5, alpha=0.5)\n",
    "\n",
    "ax1.set_xlabel('Index', fontsize=16)\n",
    "ax1.set_ylabel('Value', fontsize=16)\n",
    "ax1.legend(fontsize=14)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# Plot 2: DTW Accumulated Cost Matrix with Optimal Warping Path\n",
    "# =========================\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 8))\n",
    "cax = ax2.imshow(accumulated_cost, origin='lower', cmap='Blues', interpolation='nearest', aspect='auto',\n",
    "                 extent=[-0.5, len(sequence_b) - 0.5, -0.5, len(sequence_a) - 0.5])\n",
    "cbar = fig2.colorbar(cax, ax=ax2, label='Accumulated Cost', fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Accumulated Cost', fontsize=16)\n",
    "\n",
    "ax2.plot(path[:, 1], path[:, 0], 'r', linewidth=2, label='Optimal Warping Path')\n",
    "\n",
    "# Annotate each cell with its cost value\n",
    "for i in range(len(sequence_a)):\n",
    "    for j in range(len(sequence_b)):\n",
    "        ax2.text(j, i, f'{accumulated_cost[i, j]:.1f}', ha='center', va='center', color='black', fontsize=12)\n",
    "\n",
    "ax2.set_xticks(np.arange(len(sequence_b)))\n",
    "ax2.set_yticks(np.arange(len(sequence_a)))\n",
    "ax2.set_xlim(-0.5, len(sequence_b) - 0.5)\n",
    "ax2.set_ylim(-0.5, len(sequence_a) - 0.5)\n",
    "\n",
    "ax2.set_xlabel('Sequence B Index', fontsize=16)\n",
    "ax2.set_ylabel('Sequence A Index', fontsize=16)\n",
    "ax2.legend(fontsize=14)\n",
    "\n",
    "ax2.grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot dtw alignment path + cost matrix intersection k729_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from src.visualization.plot_vehicle_tracks_in_notebook import plot_vehicle_tracks_in_notebook\n",
    "\n",
    "# =========================\n",
    "# Step 1: Define Your Sequences\n",
    "# =========================\n",
    "\n",
    "track_id_a = 48\n",
    "track_id_b = 7\n",
    "x_a = np.array(df_cuid_grouped['x'][track_id_a])\n",
    "y_a = np.array(df_cuid_grouped['y'][track_id_a])\n",
    "x_b = np.array(df_cuid_grouped['x'][track_id_b])\n",
    "y_b = np.array(df_cuid_grouped['y'][track_id_b])\n",
    "\n",
    "# =========================\n",
    "# Step 2: Compute the Cost Matrix\n",
    "# =========================\n",
    "\n",
    "sequence_a_points = np.column_stack((x_a, y_a))\n",
    "sequence_b_points = np.column_stack((x_b, y_b))\n",
    "cost_matrix = cdist(sequence_a_points, sequence_b_points, metric='euclidean')\n",
    "\n",
    "# =========================\n",
    "# Step 3: Compute the Accumulated Cost Matrix (DTW Matrix)\n",
    "# =========================\n",
    "\n",
    "len_a, len_b = len(sequence_a_points), len(sequence_b_points)\n",
    "accumulated_cost = np.full((len_a, len_b), np.inf)\n",
    "accumulated_cost[0, 0] = cost_matrix[0, 0]\n",
    "\n",
    "for j in range(1, len_b):\n",
    "    accumulated_cost[0, j] = cost_matrix[0, j] + accumulated_cost[0, j-1]\n",
    "for i in range(1, len_a):\n",
    "    accumulated_cost[i, 0] = cost_matrix[i, 0] + accumulated_cost[i-1, 0]\n",
    "for i in range(1, len_a):\n",
    "    for j in range(1, len_b):\n",
    "        accumulated_cost[i, j] = cost_matrix[i, j] + min(\n",
    "            accumulated_cost[i-1, j-1], \n",
    "            accumulated_cost[i-1, j],    \n",
    "            accumulated_cost[i, j-1]     \n",
    "        )\n",
    "\n",
    "# =========================\n",
    "# Step 4: Compute the Optimal Warping Path\n",
    "# =========================\n",
    "\n",
    "i, j = len_a - 1, len_b - 1\n",
    "path = [(i, j)]\n",
    "while i > 0 or j > 0:\n",
    "    if i == 0:\n",
    "        j -= 1\n",
    "    elif j == 0:\n",
    "        i -= 1\n",
    "    else:\n",
    "        choices = [\n",
    "            accumulated_cost[i-1, j-1],\n",
    "            accumulated_cost[i-1, j],\n",
    "            accumulated_cost[i, j-1]\n",
    "        ]\n",
    "        move = np.argmin(choices)\n",
    "        if move == 0:\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif move == 1:\n",
    "            i -= 1\n",
    "        else:\n",
    "            j -= 1\n",
    "    path.append((i, j))\n",
    "path = np.array(path[::-1])\n",
    "\n",
    "# =========================\n",
    "# Plot 1: Sequences Alignment with DTW Path\n",
    "# =========================\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(10, 10))\n",
    "plot_vehicle_tracks_in_notebook(ax1, df_cuid, df_cuid_grouped, color='gray', alpha=0.1)\n",
    "ax1.plot(x_a, y_a, marker='o', label=f'Sequence track_id {track_id_a}', color='blue')\n",
    "ax1.plot(x_b, y_b, marker='s', label=f'Sequence track_id {track_id_b}', color='green')\n",
    "\n",
    "for (i, j) in path:\n",
    "    ax1.plot([x_a[i], x_b[j]], [y_a[i], y_b[j]], 'r--', linewidth=1.5)\n",
    "\n",
    "# ax1.set_xlabel('X', fontsize=16)\n",
    "# ax1.set_ylabel('Y', fontsize=16)\n",
    "# ax1.legend(fontsize=14)\n",
    "# set xtick fontsize\n",
    "ax1.tick_params(axis='x', labelsize=16)\n",
    "# set ytick fontsize\n",
    "ax1.tick_params(axis='y', labelsize=16)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "# ax1.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "# =========================\n",
    "# Plot 2: DTW Accumulated Cost Matrix with Optimal Warping Path\n",
    "# =========================\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 10))\n",
    "cax = ax2.imshow(accumulated_cost, origin='lower', cmap='Blues', interpolation='nearest', aspect='auto',\n",
    "                 extent=[-0.5, len_b - 0.5, -0.5, len_a - 0.5])\n",
    "cbar = fig2.colorbar(cax, ax=ax2, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Accumulated Cost', fontsize=14)\n",
    "\n",
    "ax2.plot(path[:,1], path[:,0], 'r', linewidth=2, label='Optimal Warping Path')\n",
    "ax2.set_xlabel(f'Sequence track_id {track_id_b} index', fontsize=16)\n",
    "ax2.set_ylabel(f'Sequence track_id {track_id_a} index', fontsize=16)\n",
    "ax2.legend(fontsize=14)\n",
    "\n",
    "ax2.set_xticks(np.arange(0, len_b, 5))\n",
    "ax2.set_yticks(np.arange(0, len_a, 5))\n",
    "ax2.set_xlim(-0.5, len_b - 0.5)\n",
    "ax2.set_ylim(-0.5, len_a - 0.5)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot optics + reachability plot k729_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import OPTICS\n",
    "\n",
    "# =========================\n",
    "# Step 1: Define Your Data\n",
    "# =========================\n",
    "\n",
    "# Example data: list of lists containing (x, y) tuples\n",
    "# Replace this with your actual data\n",
    "data = list_x_y_tuples\n",
    "\n",
    "# =========================\n",
    "# Step 2: Flatten the Data\n",
    "# =========================\n",
    "\n",
    "# Flatten the list of lists into a single list of (x, y) tuples\n",
    "flattened_data = [point for sequence in data for point in sequence]\n",
    "\n",
    "# Convert the list of tuples into a NumPy array\n",
    "X = np.array(flattened_data)  # Shape: (n_points, 2)\n",
    "\n",
    "# =========================\n",
    "# Step 3: Apply OPTICS Clustering\n",
    "# =========================\n",
    "\n",
    "# Initialize OPTICS with desired parameters\n",
    "# Adjust min_samples and min_cluster_size based on your data's characteristics\n",
    "optics_model = OPTICS(min_samples=7,\n",
    "                      cluster_method='dbscan',\n",
    "                      metric='manhattan',\n",
    "                      max_eps=4.9)\n",
    "\n",
    "# Fit the OPTICS model to the data\n",
    "optics_model.fit(X_intersection)\n",
    "\n",
    "# Extract reachability distances and the ordering of points\n",
    "reachability = optics_model.reachability_\n",
    "ordering = optics_model.ordering_\n",
    "clusters = optics_model.labels_\n",
    "\n",
    "# =========================\n",
    "# Step 4: Handle NaN or Inf in Reachability\n",
    "# =========================\n",
    "\n",
    "# Check for NaN or Inf in reachability distances\n",
    "if np.any(np.isnan(reachability)):\n",
    "    print(\"Warning: Reachability distances contain NaN values. Replacing them with the maximum finite reachability distance.\")\n",
    "    # Replace NaN with the maximum finite reachability distance\n",
    "    max_finite_reach = np.max(reachability[np.isfinite(reachability)])\n",
    "    reachability = np.where(np.isnan(reachability), max_finite_reach + 1, reachability)\n",
    "\n",
    "if np.any(np.isinf(reachability)):\n",
    "    print(\"Warning: Reachability distances contain Inf values. Replacing them with the maximum finite reachability distance.\")\n",
    "    # Replace Inf with a value slightly larger than the maximum finite reachability distance\n",
    "    max_finite_reach = np.max(reachability[np.isfinite(reachability)])\n",
    "    reachability = np.where(np.isinf(reachability), max_finite_reach + 1, reachability)\n",
    "\n",
    "# =========================\n",
    "# Step 5: Plot Reachability Plot and Clustering Results\n",
    "# =========================\n",
    "\n",
    "# Create a figure with two vertically stacked subplots\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(10, 10))  # Adjust figsize as needed\n",
    "fig, ax2 = plt.subplots(1, 1, figsize=(10, 10))  # Adjust figsize as needed\n",
    "\n",
    "# -------------------------\n",
    "# Top Subplot: Reachability Plot\n",
    "# -------------------------\n",
    "\n",
    "# Define unique labels (clusters)\n",
    "unique_labels = np.unique(clusters)\n",
    "n_clusters = len(unique_labels) - (1 if -1 in clusters else 0)  # Exclude noise\n",
    "\n",
    "# Generate colors for clusters, excluding noise\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, n_clusters))\n",
    "\n",
    "# Create a color mapping for clusters\n",
    "color_dict = {label: color for label, color in zip(unique_labels[unique_labels != -1], colors)}\n",
    "color_dict[-1] = 'gray'  # Assign gray color for noise\n",
    "\n",
    "# Sort reachability distances according to the ordering\n",
    "sorted_reachability = reachability[ordering]\n",
    "sorted_labels = clusters[ordering]\n",
    "sorted_colors = [color_dict[label] for label in sorted_labels]\n",
    "space = np.arange(len(X_intersection))\n",
    "\n",
    "# Plot the reachability plot with individual colors per segment\n",
    "for i in range(len(space) - 1):\n",
    "    ax1.plot(space[i:i+2], sorted_reachability[i:i+2], marker='.', linestyle='-', color=sorted_colors[i])\n",
    "\n",
    "# Fill between the reachability distances with individual colors per segment\n",
    "for i in range(len(space) - 1):\n",
    "    ax1.fill_between(space[i:i+2], sorted_reachability[i:i+2], np.min(sorted_reachability), alpha=0.3, color=sorted_colors[i])\n",
    "\n",
    "\n",
    "# Set plot limits based on reachability data\n",
    "ax1.set_ylim([0, np.max(sorted_reachability) * 1.1])\n",
    "ax1.set_xlabel('Ordered Points', fontsize=16)\n",
    "ax1.set_ylabel('Reachability Distance', fontsize=16)\n",
    "ax1.grid(True, alpha=0.1)\n",
    "\n",
    "# -------------------------\n",
    "# Bottom Subplot: Cluster Extraction Plot\n",
    "# -------------------------\n",
    "\n",
    "# Assign black color for noise if present\n",
    "if -1 in clusters:\n",
    "    color_dict[-1] = [0, 0, 0, 1]  # Black color for noise\n",
    "\n",
    "# Plot each cluster\n",
    "for label in unique_labels:\n",
    "    class_member_mask = (clusters == label)\n",
    "    xy = X_intersection[class_member_mask]\n",
    "    \n",
    "    if label == -1:\n",
    "        # Plot noise\n",
    "        ax2.plot(xy[:, 0], xy[:, 1], 'o',\n",
    "                 color='gray',\n",
    "                 markersize=6,\n",
    "                 label='Noise',\n",
    "                 zorder=100)\n",
    "    else:\n",
    "        # Plot clustered points\n",
    "        ax2.plot(xy[:, 0], xy[:, 1], 'o',\n",
    "                 color=tuple(color_dict[label]),\n",
    "                 markersize=6,\n",
    "                 label=f'Cluster {label}',\n",
    "                 zorder=100)\n",
    "\n",
    "# Set plot limits based on data\n",
    "all_x = X[:, 0]\n",
    "all_y = X[:, 1]\n",
    "ax2.set_xlim([np.min(all_x) - 1, np.max(all_x) + 1])\n",
    "ax2.set_ylim([np.min(all_y) - 1, np.max(all_y) + 1])\n",
    "plot_vehicle_tracks_in_notebook(ax2, df_cuid, df_cuid_grouped, color='gray', alpha=0.1)\n",
    "\n",
    "# Set labels and title\n",
    "ax2.set_xlabel('X', fontsize=16)\n",
    "ax2.set_ylabel('Y', fontsize=16)\n",
    "ax2.legend(loc='best', fontsize=16)\n",
    "ax2.grid(True, alpha=0.1)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Final Adjustments and Show Plot\n",
    "# =========================\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot vehicle paths k729_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "track_id = 69\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "# Plot background vehicle tracks with customized appearance\n",
    "plot_vehicle_tracks_in_notebook(ax, df_cuid, df_cuid_grouped, color='gray', alpha=0.3)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight the specific vehicle track with a larger linewidth and red color\n",
    "ax.plot(df_cuid_grouped['x'][track_id], df_cuid_grouped['y'][track_id], \n",
    "        color='red', linestyle='-', linewidth=3, label=f'vehicle_id {track_id}')\n",
    "\n",
    "# Adjust label sizes, legend, and tick parameters\n",
    "ax.set_xlabel('X', fontsize=16)\n",
    "ax.set_ylabel('Y', fontsize=16)\n",
    "ax.legend(fontsize=14)\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "# Repeat for another track ID\n",
    "track_id = 4\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "plot_vehicle_tracks_in_notebook(ax, df_cuid, df_cuid_grouped, color='gray', alpha=0.3)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax.plot(df_cuid_grouped['x'][track_id], df_cuid_grouped['y'][track_id], \n",
    "        color='red', linestyle='-', linewidth=3, label=f'vehicle_id {track_id}')\n",
    "\n",
    "ax.set_xlabel('X', fontsize=16)\n",
    "ax.set_ylabel('Y', fontsize=16)\n",
    "ax.legend(fontsize=14)\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot vehicle paths k733_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set track_id for demonstration and display length of x-coordinates for verification\n",
    "track_id = 43\n",
    "print(\"Number of points:\", len(df_cuid_grouped['x'][track_id]))\n",
    "\n",
    "# Define colors for plotting\n",
    "colors = ['blue', 'green', 'red', 'purple', 'orange', 'brown', 'pink', 'gray', 'olive', 'cyan']\n",
    "\n",
    "# Set up the figure and axis with increased figure size\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "# Highlight specific points in the track as potential outliers with larger, distinct markers\n",
    "for i, (x, y) in enumerate(zip(df_cuid_grouped['x'][track_id], df_cuid_grouped['y'][track_id])):\n",
    "    if i in range(121, 143) and i % 2 == 0:  # Highlight every other point in the range\n",
    "        label = ''\n",
    "        if i == 142:\n",
    "            label = f'Point outliers for vehicle_id {track_id}'\n",
    "        ax.scatter(x, y, color='red', s=50, label=label, zorder=1000, edgecolors='white')  # Larger size for emphasis\n",
    "\n",
    "# Plot the main vehicle track with a distinct color\n",
    "ax.plot(df_cuid_grouped['x'][track_id], df_cuid_grouped['y'][track_id], \n",
    "        linestyle='-', color='blue', alpha=0.6, linewidth=2, zorder=100)\n",
    "\n",
    "# Background plot of other tracks for context\n",
    "plot_vehicle_tracks_in_notebook(ax, df_cuid, df_cuid_grouped, color='gray', alpha=0.3)\n",
    "\n",
    "# Set grid transparency, labels, legend, and tick parameters for improved readability\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlabel('X', fontsize=16)\n",
    "ax.set_ylabel('Y', fontsize=16)\n",
    "ax.legend(fontsize=14)\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot with zoomed in window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Set track_id for demonstration and display length of x-coordinates for verification\n",
    "track_id = 43\n",
    "print(\"Number of points:\", len(df_cuid_grouped['x'][track_id]))\n",
    "\n",
    "# Define colors for plotting\n",
    "colors = ['blue', 'green', 'red', 'purple', 'orange', 'brown', 'pink', 'gray', 'olive', 'cyan']\n",
    "\n",
    "# Set up the figure and axis with increased figure size\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "# Highlight specific points in the track as potential outliers with larger, distinct markers\n",
    "for i, (x, y) in enumerate(zip(df_cuid_grouped['x'][track_id], df_cuid_grouped['y'][track_id])):\n",
    "    if i in range(121, 143) and i % 2 == 0:  # Highlight every other point in the range\n",
    "        label = ''\n",
    "        if i == 142:\n",
    "            label = f'Point outliers for vehicle_id {track_id}'\n",
    "        ax.scatter(x, y, color='red', s=50, label=label, zorder=1000, edgecolors='white')  # Larger size for emphasis\n",
    "\n",
    "# Plot the main vehicle track with a distinct color\n",
    "ax.plot(df_cuid_grouped['x'][track_id], df_cuid_grouped['y'][track_id], \n",
    "        linestyle='-', color='blue', alpha=0.6, linewidth=2, zorder=100)\n",
    "\n",
    "# Background plot of other tracks for context\n",
    "plot_vehicle_tracks_in_notebook(ax, df_cuid, df_cuid_grouped, color='gray', alpha=0.3)\n",
    "\n",
    "# Set grid transparency, labels, legend, and tick parameters for improved readability\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlabel('X', fontsize=16)\n",
    "ax.set_ylabel('Y', fontsize=16)\n",
    "ax.legend(fontsize=14)\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "# Define the zoom area coordinates\n",
    "x_min = min(df_cuid_grouped['x'][track_id][121:143]) - 5\n",
    "x_max = max(df_cuid_grouped['x'][track_id][121:143]) + 5\n",
    "y_min = min(df_cuid_grouped['y'][track_id][121:143]) - 5\n",
    "y_max = max(df_cuid_grouped['y'][track_id][121:143]) + 5\n",
    "\n",
    "# Create inset for zoomed-in area with a red border, placing it toward the bottom left\n",
    "inset_ax = inset_axes(ax, width=\"50%\", height=\"50%\", loc=\"lower left\", borderpad=2)\n",
    "inset_ax.plot(df_cuid_grouped['x'][track_id], df_cuid_grouped['y'][track_id], linestyle='-', color='blue', alpha=0.6, linewidth=2)\n",
    "\n",
    "# Plot the background tracks in the zoomed inset as well\n",
    "plot_vehicle_tracks_in_notebook(inset_ax, df_cuid, df_cuid_grouped, color='gray', alpha=0.3)\n",
    "\n",
    "# Highlight points in the zoomed inset\n",
    "inset_ax.scatter([df_cuid_grouped['x'][track_id][i] for i in range(121, 143) if i % 2 == 0],\n",
    "                 [df_cuid_grouped['y'][track_id][i] for i in range(121, 143) if i % 2 == 0],\n",
    "                 color='red', s=50, zorder=1000, edgecolors='white')\n",
    "\n",
    "# Set limits for zoomed inset and add a red border\n",
    "inset_ax.set_xlim(x_min, x_max)\n",
    "inset_ax.set_ylim(y_min, y_max)\n",
    "inset_ax.set_xticks([])\n",
    "inset_ax.set_yticks([])\n",
    "for spine in inset_ax.spines.values():\n",
    "    spine.set_edgecolor('red')\n",
    "    spine.set_linewidth(2)\n",
    "\n",
    "# Connect inset to main plot with red lines\n",
    "mark_inset(ax, inset_ax, loc1=2, loc2=4, fc=\"none\", ec=\"red\")\n",
    "\n",
    "# Add semi-transparent overlays to dim areas outside the zoomed-in window\n",
    "alpha_dim = 0.2  # Set lower alpha for dimming\n",
    "\n",
    "# Bottom dim\n",
    "ax.add_patch(patches.Rectangle((ax.get_xlim()[0], ax.get_ylim()[0]), ax.get_xlim()[1] - ax.get_xlim()[0], y_min - ax.get_ylim()[0], \n",
    "                               color='white', alpha=alpha_dim, zorder=2000))\n",
    "# Top dim\n",
    "ax.add_patch(patches.Rectangle((ax.get_xlim()[0], y_max), ax.get_xlim()[1] - ax.get_xlim()[0], ax.get_ylim()[1] - y_max, \n",
    "                               color='white', alpha=alpha_dim, zorder=2000))\n",
    "# Left dim\n",
    "ax.add_patch(patches.Rectangle((ax.get_xlim()[0], y_min), x_min - ax.get_xlim()[0], y_max - y_min, \n",
    "                               color='white', alpha=alpha_dim, zorder=2000))\n",
    "# Right dim\n",
    "ax.add_patch(patches.Rectangle((x_max, y_min), ax.get_xlim()[1] - x_max, y_max - y_min, \n",
    "                               color='white', alpha=alpha_dim, zorder=2000))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot itakura parallelogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyts.metrics import itakura_parallelogram\n",
    "from pyts.metrics.dtw import _get_itakura_slopes\n",
    "from tslearn.metrics import dtw_path_from_metric\n",
    "\n",
    "def plot_itakura(n_timestamps_1, n_timestamps_2, max_slope=1.):\n",
    "    \"\"\"Plot Itakura parallelogram with a light gray background and light blue highlighted region.\"\"\"\n",
    "    region = itakura_parallelogram(n_timestamps_1, n_timestamps_2, max_slope)\n",
    "    max_slope_og = max_slope\n",
    "    max_slope, min_slope = _get_itakura_slopes(\n",
    "        n_timestamps_1, n_timestamps_2, max_slope)\n",
    "    \n",
    "    # Initialize plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    mask = np.zeros((n_timestamps_2, n_timestamps_1))\n",
    "    \n",
    "    # Fill in parallelogram region with light blue color\n",
    "    for i, (j, k) in enumerate(region.T):\n",
    "        mask[j:k, i] = 1.\n",
    "    ax.imshow(mask, origin='lower', cmap='Blues', alpha=0.3)\n",
    "    ax.set_facecolor('#f7f7f7')  # Light gray background\n",
    "\n",
    "    # Set axis limits and grid\n",
    "    sz = max(n_timestamps_1, n_timestamps_2)\n",
    "    x = np.arange(-1, sz + 1)\n",
    "\n",
    "    # Define lines with modern colors\n",
    "    low_max_line = ((n_timestamps_2 - 1) - max_slope * (n_timestamps_1 - 1)) + max_slope * x\n",
    "    up_min_line = ((n_timestamps_2 - 1) - min_slope * (n_timestamps_1 - 1)) + min_slope * x\n",
    "    diag = (n_timestamps_2 - 1) / (n_timestamps_1 - 1) * x\n",
    "\n",
    "    ax.plot(x, diag, color='black', lw=1, label=\"Diagonal\")\n",
    "    ax.plot(x, max_slope * x, color='#1f77b4', lw=1.5, label=\"$Lower_1$\")\n",
    "    ax.plot(x, up_min_line, color='#d62728', lw=1.5, label=\"$Lower_2$\")\n",
    "    ax.plot(x, min_slope * x, color='#ff7f0e', lw=1.5, label=\"$Upper_1$\")\n",
    "    ax.plot(x, low_max_line, color='#2ca02c', lw=1.5, label=\"$Upper_2$\")\n",
    "\n",
    "    # Customize grid and axis settings\n",
    "    ax.set_xticks(np.arange(-.5, n_timestamps_1, 5), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, n_timestamps_2, 5), minor=True)\n",
    "    ax.grid(which='minor', color='#bfbfbf', linestyle='--', linewidth=0.5)\n",
    "    ax.set_xlim((-0.5, n_timestamps_1 - 0.5))\n",
    "    ax.set_ylim((-0.5, n_timestamps_2 - 0.5))\n",
    "\n",
    "    # Smaller legend\n",
    "    ax.legend(loc='upper left', fontsize='large')\n",
    "    plt.show()\n",
    "\n",
    "# Generate separate plots for each slope value for the (50, 25) matrix\n",
    "slopes = [1.5, 4.5]\n",
    "for slope in slopes:\n",
    "    plot_itakura(50, 25, max_slope=slope)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create plot of feature list lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the length of each list in df_cuid_grouped['x']\n",
    "lengths = df_cuid_grouped['x'].apply(len)\n",
    "\n",
    "# Truncate lengths at 200 by capping values greater than 200\n",
    "cutoff = 200\n",
    "lengths_truncated = lengths.apply(lambda x: x if x <= cutoff else cutoff)\n",
    "\n",
    "# Plotting the histogram with the x-axis starting at 0\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(lengths_truncated, color='b', bins=50, edgecolor='white')\n",
    "plt.xlabel(\"Time Series Length\", fontsize=16)\n",
    "plt.ylabel(\"Frequency\", fontsize=16)\n",
    "\n",
    "# Set x-ticks, starting from 0, and label the last one as \">cutoff\"\n",
    "xticks = np.arange(0, cutoff + 10, 20)  # Custom ticks from 0 to cutoff\n",
    "xticks = np.append(xticks, cutoff)  # Ensure the last tick is cutoff\n",
    "plt.xticks(xticks, labels=[f\">{cutoff}\" if x == cutoff else str(int(x)) for x in xticks], fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xlim(left=0)  # Start x-axis from 0\n",
    "plt.grid(True, alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot dtw distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dtw_distance_matrix_path = f'{code_root_dir}/data/processed/{intersection_name}_diff_itakura_slope_dtw_matrices.json'\n",
    "\n",
    "# Load DTW distance matrix data\n",
    "with open(dtw_distance_matrix_path) as f:\n",
    "    dtw_distance_matrix = json.load(f)\n",
    "\n",
    "# Choose a random key from the DTW matrix keys\n",
    "dtw_keys = list(dtw_distance_matrix.keys())\n",
    "# dtw_key = np.random.choice(dtw_keys, 1)[0]\n",
    "dtw_key = 'itakura_2.60_dist_euclidean'\n",
    "\n",
    "\n",
    "# Set font size globally\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "# Plot the DTW distance matrix\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "dtw_dist_matrix = np.array(dtw_distance_matrix[dtw_key])\n",
    "np.fill_diagonal(dtw_dist_matrix, np.nan)\n",
    "cax = ax.imshow(dtw_dist_matrix, cmap='Blues', vmin=0, vmax=500)\n",
    "fig.colorbar(cax, ax=ax)\n",
    "\n",
    "# Set labels with fontsize 16\n",
    "ax.set_xlabel(\"Index\", fontsize=16)\n",
    "ax.set_ylabel(\"Index\", fontsize=16)\n",
    "\n",
    "# Print information\n",
    "print(intersection_name)\n",
    "print(f'{dtw_key}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot optics start end with medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save to JSON\n",
    "file_path = f'{code_root_dir}/src/models/OUTLIER_DETECTION/OPTICS_MODELS/{intersection_name}_optics_optimized_params.json'\n",
    "print(file_path)\n",
    "with open(file_path) as f:\n",
    "    optimization_params = json.load(f)\n",
    "print(optimization_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_params_silhouette = optimization_params['davies_bouldin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.ensure_distance_metric_params import ensure_distance_metric_params\n",
    "from src.models.DISTANCE_METRICS_WITH_ADDITIONAL_ARGS import DISTANCE_METRICS_WITH_ADDITIONAL_ARGS\n",
    "max_eps = optimization_params_silhouette['epsilon']\n",
    "min_samples = optimization_params_silhouette['min_samples']\n",
    "metric = optimization_params_silhouette['metric']\n",
    "cluster_method = optimization_params_silhouette['cluster_method']\n",
    "\n",
    "xi = optimization_params_silhouette['xi'] if cluster_method == 'xi' else 1\n",
    "\n",
    "if metric in DISTANCE_METRICS_WITH_ADDITIONAL_ARGS:\n",
    "    metric_params = ensure_distance_metric_params(X_intersection,[metric])\n",
    "    optics_model = OPTICS(min_samples=min_samples,\n",
    "                        cluster_method=cluster_method,\n",
    "                        metric=metric,\n",
    "                        max_eps=max_eps,\n",
    "                        xi=xi,\n",
    "                        metric_params=metric_params[metric]\n",
    "                        )\n",
    "else:\n",
    "    metric_params = {}\n",
    "    optics_model = OPTICS(min_samples=min_samples,\n",
    "                        cluster_method=cluster_method,\n",
    "                        metric=metric,\n",
    "                        max_eps=max_eps,\n",
    "                        xi=xi\n",
    "                        )\n",
    "\n",
    "print(metric_params)\n",
    "\n",
    "optics_model.fit(X_intersection)\n",
    "\n",
    "# Extract reachability distances and the ordering of points\n",
    "reachability = optics_model.reachability_\n",
    "ordering = optics_model.ordering_\n",
    "clusters = optics_model.labels_\n",
    "\n",
    "fig, ax2 = plt.subplots(1, 1, figsize=(10, 10))  # Adjust figsize as needed\n",
    "\n",
    "# Define unique labels (clusters)\n",
    "unique_labels = np.unique(clusters)\n",
    "n_clusters = len(unique_labels) - (1 if -1 in clusters else 0)  # Exclude noise\n",
    "\n",
    "# Generate colors for clusters, excluding noise\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, n_clusters))\n",
    "\n",
    "# Create a color mapping for clusters\n",
    "color_dict = {label: color for label, color in zip(unique_labels[unique_labels != -1], colors)}\n",
    "color_dict[-1] = 'gray'  # Assign gray color for noise\n",
    "\n",
    "# Sort reachability distances according to the ordering\n",
    "sorted_reachability = reachability[ordering]\n",
    "sorted_labels = clusters[ordering]\n",
    "sorted_colors = [color_dict[label] for label in sorted_labels]\n",
    "space = np.arange(len(X_intersection))\n",
    "\n",
    "# Assign black color for noise if present\n",
    "if -1 in clusters:\n",
    "    color_dict[-1] = [0, 0, 0, 1]  # Black color for noise\n",
    "\n",
    "# Plot each cluster\n",
    "for label in unique_labels:\n",
    "    class_member_mask = (clusters == label)\n",
    "    xy = X_intersection[class_member_mask]\n",
    "    \n",
    "    if label == -1:\n",
    "        # Plot noise\n",
    "        ax2.plot(xy[:, 0], xy[:, 1], 'o',\n",
    "                 color='gray',\n",
    "                 markersize=6,\n",
    "                 label='Noise',\n",
    "                 zorder=100)\n",
    "    else:\n",
    "        # Plot clustered points\n",
    "        ax2.plot(xy[:, 0], xy[:, 1], 'o',\n",
    "                 color=tuple(color_dict[label]),\n",
    "                 markersize=6,\n",
    "                 label=f'Cluster {label}',\n",
    "                 zorder=100)\n",
    "\n",
    "# Set plot limits based on data\n",
    "plot_vehicle_tracks_in_notebook(ax2, df_cuid, df_cuid_grouped, color='gray', alpha=0.1)\n",
    "\n",
    "# ******************\n",
    "# Calc medoids\n",
    "# ******************\n",
    "\n",
    "from src.models.optics.calculate_cluster_medoids import calculate_cluster_medoids\n",
    "print(len(X_intersection))\n",
    "medoids = calculate_cluster_medoids(X_intersection, optics_model)\n",
    "label_flag = False\n",
    "for medoid in medoids:\n",
    "    if not label_flag:\n",
    "        ax2.plot(medoid[0], medoid[1], 'X', color='r', markersize=10, label='Medoid', zorder=10000)\n",
    "        label_flag = True\n",
    "    ax2.plot(medoid[0], medoid[1], 'X', color='r', markersize=10, zorder=10000)\n",
    "\n",
    "# # Set labels and title\n",
    "# ax2.set_xlabel('X', fontsize=16)\n",
    "# ax2.set_ylabel('Y', fontsize=16)\n",
    "# ax2.legend(loc='best', fontsize=10)\n",
    "# ax2.grid(True, alpha=0.1)\n",
    "# # create tuple list of vehicle track 43 for k733_2018\n",
    "# track_no = 102\n",
    "# track_all = df_cuid_grouped.iloc[track_no]\n",
    "# track_x = track_all['x']\n",
    "# track_y = track_all['y']\n",
    "# ax2.plot(track_x, track_y, color='red', linestyle='-', linewidth=2)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Final Adjustments and Show Plot\n",
    "# =========================\n",
    "\n",
    "print(intersection_name)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot optimized dtw clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### see: notebooks/exploratory/plot_optimized_dtw_optics.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot subclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.visualization.plot_within_cluster_optics import plot_within_cluster_optics\n",
    "\n",
    "\n",
    "# if intersection_name=='k729_2022':\n",
    "#     intersection_name_k729_2022 = 'k729_2022'\n",
    "#     params_uid_k729_2022 = 'WDB'\n",
    "#     cluster_label_k729_2022 = 2\n",
    "#     eval_metric_k729_2022 = 'silhouette'\n",
    "#     within_cluster_params_uid_k729_2022 = 'SDB'\n",
    "#     for cluster_label in range(0,10):\n",
    "#         plot_within_cluster_optics(intersection_name_k729_2022, params_uid_k729_2022, cluster_label, eval_metric_k729_2022, within_cluster_params_uid_k729_2022)\n",
    "    \n",
    "# if intersection_name=='k733_2018':\n",
    "#     within_cluster_optimization_init_params_id_k733_2018 = 'NCB'\n",
    "#     intersection_name_k733_2018 = 'k733_2018'\n",
    "#     intersection_optics_params_uid_k733_2018 = None\n",
    "#     eval_metric_k733_2018 = 'silhouette'\n",
    "#     for cluster_label in range(0,7):\n",
    "#         plot_within_cluster_optics(intersection_name_k733_2018, intersection_optics_params_uid_k733_2018, cluster_label, eval_metric_k733_2018, within_cluster_optimization_init_params_id_k733_2018)\n",
    "\n",
    "# if intersection_name=='k733_2020':\n",
    "#     within_cluster_optimization_init_params_id_k733_2020 = 'NCB'\n",
    "#     intersection_name_k733_2020 = 'k733_2020'\n",
    "#     intersection_optics_params_uid_k733_2020 = None\n",
    "#     eval_metric_k733_2020 = 'silhouette'\n",
    "#     for cluster_label in range(0,5):\n",
    "#         plot_within_cluster_optics(intersection_name_k733_2020, intersection_optics_params_uid_k733_2020, cluster_label, eval_metric_k733_2020, within_cluster_optimization_init_params_id_k733_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "plot_vehicle_tracks_in_notebook(ax, df_cuid, df_cuid_grouped, color='gray', alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot start and end points w/ scores within cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save to JSON\n",
    "file_path = f'{code_root_dir}/src/models/OUTLIER_DETECTION/OPTICS_MODELS/{intersection_name}_optics_optimized_params.json'\n",
    "print(file_path)\n",
    "with open(file_path) as f:\n",
    "    optimization_params = json.load(f)\n",
    "print(optimization_params)\n",
    "optimization_params_silhouette = optimization_params['calinski_harabasz']\n",
    "from src.models.ensure_distance_metric_params import ensure_distance_metric_params\n",
    "from src.models.DISTANCE_METRICS_WITH_ADDITIONAL_ARGS import DISTANCE_METRICS_WITH_ADDITIONAL_ARGS\n",
    "max_eps = optimization_params_silhouette['epsilon']\n",
    "min_samples = optimization_params_silhouette['min_samples']\n",
    "metric = optimization_params_silhouette['metric']\n",
    "cluster_method = optimization_params_silhouette['cluster_method']\n",
    "\n",
    "xi = optimization_params_silhouette['xi'] if cluster_method == 'xi' else 1\n",
    "\n",
    "if metric in DISTANCE_METRICS_WITH_ADDITIONAL_ARGS:\n",
    "    metric_params = ensure_distance_metric_params(X_intersection,[metric])\n",
    "    optics_model = OPTICS(min_samples=min_samples,\n",
    "                        cluster_method=cluster_method,\n",
    "                        metric=metric,\n",
    "                        max_eps=max_eps,\n",
    "                        xi=xi,\n",
    "                        metric_params=metric_params[metric]\n",
    "                        )\n",
    "else:\n",
    "    metric_params = {}\n",
    "    optics_model = OPTICS(min_samples=min_samples,\n",
    "                        cluster_method=cluster_method,\n",
    "                        metric=metric,\n",
    "                        max_eps=max_eps,\n",
    "                        xi=xi\n",
    "                        )\n",
    "\n",
    "print(metric_params)\n",
    "\n",
    "optics_model.fit(X_intersection)\n",
    "\n",
    "clusters = optics_model.labels_\n",
    "\n",
    "fig, ax2 = plt.subplots(1, 1, figsize=(10, 10))  # Adjust figsize as needed\n",
    "\n",
    "# Define unique labels (clusters)\n",
    "unique_labels = np.unique(clusters)\n",
    "n_clusters = len(unique_labels) - (1 if -1 in clusters else 0)  # Exclude noise\n",
    "\n",
    "# Generate colors for clusters, excluding noise\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, n_clusters))\n",
    "\n",
    "# Create a color mapping for clusters\n",
    "color_dict = {label: color for label, color in zip(unique_labels[unique_labels != -1], colors)}\n",
    "color_dict[-1] = 'gray'  # Assign gray color for noise\n",
    "\n",
    "# Sort reachability distances according to the ordering\n",
    "sorted_reachability = reachability[ordering]\n",
    "sorted_labels = clusters[ordering]\n",
    "sorted_colors = [color_dict[label] for label in sorted_labels]\n",
    "space = np.arange(len(X_intersection))\n",
    "\n",
    "# Assign black color for noise if present\n",
    "if -1 in clusters:\n",
    "    color_dict[-1] = [0, 0, 0, 1]  # Black color for noise\n",
    "\n",
    "alpha_val = .2\n",
    "\n",
    "# Plot each cluster\n",
    "for label in unique_labels:\n",
    "    class_member_mask = (clusters == label)\n",
    "    xy = X_intersection[class_member_mask]\n",
    "    \n",
    "    if label == -1:\n",
    "        # Plot noise\n",
    "        ax2.plot(xy[:, 0], xy[:, 1], 'o',\n",
    "                 color='gray',\n",
    "                 markersize=6,\n",
    "                 label='Noise',\n",
    "                 zorder=100,\n",
    "                 alpha=alpha_val)\n",
    "    else:\n",
    "        # Plot clustered points\n",
    "        ax2.plot(xy[:, 0], xy[:, 1], 'o',\n",
    "                 color=tuple(color_dict[label]),\n",
    "                 markersize=6,\n",
    "                 label=f'Cluster {label}',\n",
    "                 zorder=100,\n",
    "                 alpha=alpha_val)\n",
    "\n",
    "# Set plot limits based on data\n",
    "plot_vehicle_tracks_in_notebook(ax2, df_cuid, df_cuid_grouped, color='gray', alpha=0.1)\n",
    "\n",
    "# ******************\n",
    "# Calc medoids\n",
    "# ******************\n",
    "\n",
    "alpha_medoids = .5\n",
    "\n",
    "from src.models.optics.calculate_cluster_medoids import calculate_cluster_medoids\n",
    "print(len(X_intersection))\n",
    "medoids = calculate_cluster_medoids(X_intersection, optics_model)\n",
    "label_flag = False\n",
    "for medoid in medoids:\n",
    "    if not label_flag:\n",
    "        ax2.plot(medoid[0], medoid[1], 'X', color='r', markersize=10, label='Medoid', zorder=10000, alpha=alpha_medoids)\n",
    "        label_flag = True\n",
    "    ax2.plot(medoid[0], medoid[1], 'X', color='r', markersize=10, zorder=10000, alpha=alpha_medoids)\n",
    "\n",
    "# Set labels and title\n",
    "ax2.set_xlabel('X', fontsize=16)\n",
    "ax2.set_ylabel('Y', fontsize=16)\n",
    "ax2.grid(True, alpha=0.1)\n",
    "# create tuple list of vehicle track 43 for k733_2018\n",
    "track_no = 102\n",
    "track_all = df_cuid_grouped.iloc[track_no]\n",
    "track_x = track_all['x']\n",
    "track_y = track_all['y']\n",
    "x_start = track_all['x'][0]\n",
    "y_start = track_all['y'][0]\n",
    "x_end = track_all['x'][-1]\n",
    "y_end = track_all['y'][-1]\n",
    "ax2.plot(track_x, track_y, color='black', linestyle='-', linewidth=4, alpha=1, zorder=100000)\n",
    "ax2.plot(x_start, y_start, 'o', color='green', markersize=12, label='Start', zorder=100000)\n",
    "ax2.plot(x_end, y_end, 'o', color='red', markersize=12, label='End', zorder=100000)\n",
    "ax2.legend(loc='best', fontsize=10)\n",
    "# add text below plot\n",
    "start_score = 0.44966442953020136\n",
    "end_score = 0.2818791946308724\n",
    "\n",
    "fig.text(0.32, -0.02, f'Start Point Outlier Probability Score:      {start_score:.4f}', ha='center', fontsize=16)\n",
    "fig.text(0.32, -0.05, f'End Point Outlier Probability Score:        {end_score:.4f}', ha='center', fontsize=16)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Final Adjustments and Show Plot\n",
    "# =========================\n",
    "\n",
    "print(intersection_name)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot path w/ path score w/ subclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.get_x_y_tuple_list import get_x_y_tuple_list\n",
    "from src.visualization.render_vehicle_track_cluster_in_notebook import render_vehicle_track_cluster_in_notebook\n",
    "from src.models.optics.get_clusters_from_optics_labels import get_clusters_from_optics_labels\n",
    "from src.visualization.plot_vehicle_tracks_in_notebook import plot_vehicle_tracks_in_notebook\n",
    "\n",
    "\n",
    "def plot_within_cluster_optics(intersection_name, params_uid, cluster_label, eval_metric, within_cluster_params_uid=None):\n",
    "\n",
    "    print(f'------------------------within CLUSTER #{cluster_label} for INTERSECTION {intersection_name}------------------------')\n",
    "\n",
    "    # get data\n",
    "    data_path = f'{code_root_dir}/data/processed/{intersection_name}_cuid.csv'\n",
    "    df_cuid = pd.read_csv(data_path)\n",
    "    df_cuid_grouped_path = data_path.replace('.csv', '_grouped.csv')\n",
    "    df_cuid_grouped = pd.read_csv(df_cuid_grouped_path)\n",
    "    df_cuid_grouped['x'] = df_cuid_grouped['x'].apply(lambda x: ast.literal_eval(x))\n",
    "    df_cuid_grouped['y'] = df_cuid_grouped['y'].apply(lambda y: ast.literal_eval(y))\n",
    "    list_x_y_tuples = get_x_y_tuple_list(df_cuid_grouped, ['x','y'])\n",
    "\n",
    "    # ----------------- UNDERLYING OPTICS -----------------\n",
    "    def get_optics_params(optics_params, metric):\n",
    "        optics_params = optics_params[metric]\n",
    "        dtw_dist_matrix_key = optics_params['dtw_key']\n",
    "        max_eps = optics_params['epsilon']\n",
    "        min_samples = optics_params['min_samples']\n",
    "        cluster_method = optics_params['cluster_method']\n",
    "        xi = optics_params['xi']\n",
    "        kwargs = {\n",
    "            'max_eps': max_eps,\n",
    "            'min_samples': min_samples,\n",
    "            'cluster_method': cluster_method,\n",
    "            'xi': xi\n",
    "        }\n",
    "        filtered_kwargs = {k: v for k, v in kwargs.items() if v is not None}\n",
    "        return dtw_dist_matrix_key, filtered_kwargs\n",
    "    \n",
    "    # check for params uid\n",
    "    if params_uid is not None:\n",
    "        opt_params_path = f'{code_root_dir}/data/processed/{intersection_name}_optics_vehicle_paths_optimized_params_{params_uid}.json'\n",
    "    else:\n",
    "        opt_params_path = f'{code_root_dir}/data/processed/{intersection_name}_optics_vehicle_paths_optimized_params.json'\n",
    "    with open(opt_params_path, 'r') as f:\n",
    "        optics_params = json.load(f)\n",
    "\n",
    "    # import optimized parameters\n",
    "    dtw_matrix_key, kwargs_acc_score = get_optics_params(optics_params, eval_metric)\n",
    "\n",
    "    # import dtw distance matrix\n",
    "    dtw_distance_matrix_path = f'{code_root_dir}/data/processed/{intersection_name}_diff_itakura_slope_dtw_matrices.json'\n",
    "    with open(dtw_distance_matrix_path) as f:\n",
    "        dtw_distance_matrices_dict = json.load(f)\n",
    "\n",
    "    # get the distance matrix\n",
    "    dtw_distance_matrix = dtw_distance_matrices_dict[dtw_matrix_key]\n",
    "\n",
    "    # create optics model\n",
    "    optics_model = OPTICS(metric='precomputed', **kwargs_acc_score).fit(dtw_distance_matrix)\n",
    "\n",
    "    # get labels for big models\n",
    "    labels = get_clusters_from_optics_labels(optics_model.labels_)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # ----------------- WITHIN CLUSTER OPTICS -----------------\n",
    "    # path to optimized within cluster optics params\n",
    "    path_optimized_in_cluster_optics_params = f'{code_root_dir}/data/processed/within_cluster_clustering_optimization/{intersection_name}_optics_optimized_vehicle_paths_{params_uid}_{eval_metric}_within_cluster_{cluster_label}_optimized_params_{within_cluster_params_uid}.json'\n",
    "\n",
    "    # load optimized within cluster optics params\n",
    "    try:\n",
    "        with open(path_optimized_in_cluster_optics_params, 'r') as f:\n",
    "            within_cluster_optics_params = json.load(f)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f'File not found: {path_optimized_in_cluster_optics_params}')\n",
    "        _, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "        # filter labels to include whole cluster\n",
    "        render_vehicle_track_cluster_in_notebook(ax, df_cuid, df_cuid_grouped, {'0': labels[cluster_label]})\n",
    "        plot_vehicle_tracks_in_notebook(ax, df_cuid, df_cuid_grouped, color='gray', alpha=0.5, title=f'Intersection: {intersection_name} \\n No within cluster optimization found for cluster #{cluster_label}')\n",
    "        return\n",
    "    \n",
    "    # extract within cluster optics params according to eval metric\n",
    "    within_cluster_optics_params = within_cluster_optics_params[eval_metric]\n",
    "\n",
    "    # extract within cluster optics params\n",
    "    within_cluster_max_eps = within_cluster_optics_params['epsilon']\n",
    "    within_cluster_min_samples = within_cluster_optics_params['min_samples']\n",
    "    within_cluster_cluster_method = within_cluster_optics_params['cluster_method']\n",
    "    within_cluster_xi = within_cluster_optics_params['xi'] if within_cluster_optics_params['xi'] is not None else 0.05\n",
    "    within_cluster_dtw_key = within_cluster_optics_params['dtw_key']\n",
    "\n",
    "    # create filtered data using certain cluster\n",
    "    df_grouped_within_cluster_filtered = df_cuid_grouped.loc[optics_model.labels_ == cluster_label] \n",
    "\n",
    "    # extract optimized within cluster dtw distance matrix\n",
    "    within_cluster_dtw_distance_matrix = dtw_distance_matrices_dict[within_cluster_dtw_key]\n",
    "\n",
    "    # create within cluster dtw distance matrices by filtering only for the cluster\n",
    "    within_cluster_dtw_distance_matrix = np.array(within_cluster_dtw_distance_matrix)\n",
    "    filtered_rows = within_cluster_dtw_distance_matrix[optics_model.labels_ == cluster_label]\n",
    "    within_cluster_dtw_distance_matrix = filtered_rows[:, optics_model.labels_ == cluster_label]\n",
    "\n",
    "    # fit new within cluster optics model\n",
    "    optics_within_cluster = OPTICS(metric='precomputed', \n",
    "                                   max_eps=within_cluster_max_eps, \n",
    "                                   min_samples=within_cluster_min_samples, \n",
    "                                   cluster_method=within_cluster_cluster_method, \n",
    "                                   xi=within_cluster_xi\n",
    "                                   ).fit(within_cluster_dtw_distance_matrix)\n",
    "\n",
    "    # get labels for within cluster model\n",
    "    labels_within_cluster = get_clusters_from_optics_labels(optics_within_cluster.labels_)\n",
    "    # path_score = 0.998894239896124\n",
    "    path_score = 0.016350845506988853\n",
    "\n",
    "\n",
    "    # plot within cluster clusters\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(10,10))\n",
    "    fig.text(0.365, 0.0, f'Path Outlier Probability Score:        {path_score:.4f}', ha='center', fontsize=16)\n",
    "    # track_all = [(1.4866181033949353, -11.157597292613953), (1.6007128092120777, -11.366445569474749), (1.71480751502922, -11.575293846335542), (1.8289022208463623, -11.784142123196338), (1.9429969266635045, -11.992990400057133), (2.057091632480647, -12.201838676917927), (2.1711863382977894, -12.410686953778722), (2.2852810441149316, -12.619535230639517), (2.399375749932074, -12.82838350750031), (2.5134704557492165, -13.037231784361106), (2.627565161566359, -13.246080061221901), (2.7416598673835013, -13.454928338082695), (2.8557545732006435, -13.66377661494349), (2.9698492790177857, -13.872624891804286), (3.083943984834928, -14.08147316866508), (3.19803869065207, -14.290321445525874), (3.312133396469213, -14.499169722386668), (3.4262281022863554, -14.708017999247463), (3.5403228081034976, -14.916866276108259), (3.65441751392064, -15.125714552969054), (3.7685122197377825, -15.33456282982985), (3.8826069255549243, -15.543411106690641), (3.996701631372067, -15.752259383551436), (4.110796337189209, -15.961107660412232), (4.224891043006352, -16.169955937273027), (4.338985748823494, -16.378804214133822), (4.453080454640636, -16.587652490994614), (4.567175160457778, -16.79650076785541), (4.681269866274921, -17.005349044716205), (4.795364572092064, -17.214197321577), (4.909459277909205, -17.423045598437795), (5.023553983726348, -17.631893875298587), (5.13764868954349, -17.840742152159386), (5.2517433953606325, -18.049590429020178), (5.365838101177776, -18.258438705880973), (5.479932806994917, -18.46728698274177), (5.59402751281206, -18.676135259602564), (5.708122218629201, -18.88498353646336), (5.822216924446344, -19.09383181332415), (5.936311630263487, -19.30268009018495), (6.05040633608063, -19.51152836704574), (6.164501041897771, -19.720376643906537), (6.278595747714913, -19.929224920767332), (6.392690453532056, -20.138073197628124), (6.5067851593491985, -20.346921474488923), (6.620879865166341, -20.555769751349715), (6.734974570983483, -20.76461802821051), (6.849069276800625, -20.973466305071305), (6.963163982617768, -21.1823145819321), (7.0772586884349105, -21.391162858792896), (7.191353394252053, -21.600011135653688), (7.305448100069195, -21.808859412514487), (7.419542805886337, -22.01770768937528), (7.53363751170348, -22.226555966236074), (7.6477322175206215, -22.43540424309687), (7.761826923337765, -22.64425251995766), (7.875921629154907, -22.85310079681846), (7.990016334972049, -23.06194907367925), (8.104111040789192, -23.270797350540047), (8.218205746606333, -23.479645627400842)]\n",
    "    # track_x = [x[0] for x in track_all]\n",
    "    # track_y = [y[1] for y in track_all]\n",
    "    # axs.plot(track_x, track_y, color='red', linestyle='-', linewidth=4, alpha=1, zorder=100000)    \n",
    "    # # track_no = 102\n",
    "    track_all = df_cuid_grouped.iloc[track_no]\n",
    "    axs.plot(track_all['x'], track_all['y'], color='red', linestyle='-', linewidth=4, alpha=1, zorder=100000)\n",
    "\n",
    "    render_vehicle_track_cluster_in_notebook(axs, df_cuid, df_grouped_within_cluster_filtered, labels_within_cluster)\n",
    "    plot_vehicle_tracks_in_notebook(axs, df_cuid, df_cuid_grouped, '', color='gray', alpha=0.5)\n",
    "    # delete legend from axs\n",
    "    axs.get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_name_k729_2022 = 'k729_2022'\n",
    "params_uid_k729_2022 = 'WDB'\n",
    "eval_metric_k729_2022 = 'silhouette'\n",
    "within_cluster_params_uid_k729_2022 = 'SDB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cluster_label in range(0,10):\n",
    "#     plot_within_cluster_optics(intersection_name_k729_2022, params_uid_k729_2022, cluster_label, eval_metric_k729_2022, within_cluster_params_uid_k729_2022)\n",
    "\n",
    "cluster_label = 0\n",
    "plot_within_cluster_optics(intersection_name_k729_2022, params_uid_k729_2022, cluster_label, eval_metric_k729_2022, within_cluster_params_uid_k729_2022)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ba_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
